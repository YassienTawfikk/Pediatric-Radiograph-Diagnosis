{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pediatric Pneumonia Detection - Training Pipeline\n",
                "\n",
                "This notebook demonstrates the end-to-end training process for detecting pneumonia in pediatric chest X-rays using a ResNet-50 based architecture.\n",
                "\n",
                "## 1. Setup and Imports\n",
                "We start by setting up the environment and importing the necessary modules from our `model_core` package."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path to import model_core\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "from model_core.data_pipeline import DataPipeline\n",
                "from model_core.model_builder import ModelBuilder\n",
                "from model_core.trainer import Trainer\n",
                "from model_core.utils import Utils\n",
                "\n",
                "# Configuration\n",
                "DATASET_PATH = \"/path/to/chest_xray\"  # UPDATE THIS PATH\n",
                "OUTPUT_DIR = \"../outputs\"\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preparation\n",
                "We use the `DataPipeline` class to explore the dataset and create data generators with augmentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize pipeline\n",
                "pipeline = DataPipeline(DATASET_PATH, img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
                "\n",
                "# Explore dataset structure\n",
                "stats = pipeline.explore_dataset()\n",
                "\n",
                "# Create stratified validation split\n",
                "pipeline.create_validation_split(val_ratio=0.15)\n",
                "\n",
                "# Create data generators\n",
                "train_gen, val_gen, test_gen = pipeline.create_generators(use_augmentation=True)\n",
                "\n",
                "# Calculate class weights for imbalance handling\n",
                "class_weights = Utils.calculate_class_weights(train_gen)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Samples\n",
                "Let's look at some representative X-ray images from the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pipeline.visualize_samples()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Stage 1: Feature Extraction\n",
                "In this stage, we freeze the ResNet-50 backbone and only train the custom classification head."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build model with frozen backbone\n",
                "model = ModelBuilder.build(img_size=IMG_SIZE, trainable_backbone=False)\n",
                "ModelBuilder.compile(model, learning_rate=1e-4)\n",
                "\n",
                "# Initialize trainer\n",
                "trainer = Trainer(model, output_dir=OUTPUT_DIR)\n",
                "\n",
                "# Train Stage 1\n",
                "history1 = trainer.train(\n",
                "    train_gen, val_gen, \n",
                "    epochs=8,\n",
                "    stage='stage1',\n",
                "    class_weight=class_weights\n",
                ")\n",
                "\n",
                "# Visualize training history\n",
                "trainer.plot_history(history1, 'stage1')\n",
                "Utils.print_best_metrics(history1, 'Stage 1')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Stage 2: Fine-Tuning\n",
                "Now we unfreeze the top layers of the backbone to fine-tune the feature representations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unfreeze layers\n",
                "base_model = model.layers[1]\n",
                "base_model.trainable = True\n",
                "# Keep bottom layers frozen to prevent overfitting\n",
                "for layer in base_model.layers[:140]:\n",
                "    layer.trainable = False\n",
                "\n",
                "# Recompile with lower learning rate\n",
                "ModelBuilder.compile(model, learning_rate=1e-5)\n",
                "\n",
                "# Train Stage 2\n",
                "history2 = trainer.train(\n",
                "    train_gen, val_gen, \n",
                "    epochs=5,\n",
                "    stage='stage2',\n",
                "    class_weight=class_weights\n",
                ")\n",
                "\n",
                "# Visualize fine-tuning history\n",
                "trainer.plot_history(history2, 'stage2')\n",
                "Utils.print_best_metrics(history2, 'Stage 2')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}