{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pediatric Pneumonia Detection - Complete Pipeline\n",
                "\n",
                "This notebook implements the complete end-to-end workflow for detecting pneumonia in pediatric chest X-rays. \n",
                "\n",
                "**Workflow:**\n",
                "1.  **Data Preparation**: Download dataset from Kaggle, explore structure, and create data generators.\n",
                "2.  **Training**: Train a ResNet-50 model using specific two-stage transfer learning (Feature Extraction + Fine-Tuning).\n",
                "3.  **Evaluation**: Evaluate performance on the test set using comprehensive metrics (Accuracy, AUC, Sensitivity, Specificity).\n",
                "4.  **Explainability**: Visualize model focus regions using Grad-CAM.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "Import necessary libraries and project modules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import kagglehub\n",
                "from pathlib import Path\n",
                "\n",
                "# Add project root to path to import model_core\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "from model_core.data_pipeline import DataPipeline\n",
                "from model_core.model_builder import ModelBuilder\n",
                "from model_core.trainer import Trainer\n",
                "from model_core.evaluator import ModelEvaluator\n",
                "from model_core.gradcam import GradCAMVisualizer\n",
                "from model_core.utils import Utils\n",
                "\n",
                "# Configuration\n",
                "OUTPUT_DIR = \"../outputs\"\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preparation\n",
                "We download the dataset from Kaggle and prepare the data generators."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download latest version of the dataset\n",
                "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
                "print(\"Path to dataset files:\", path)\n",
                "\n",
                "# Set dataset path\n",
                "DATASET_PATH = os.path.join(path, \"chest_xray\")\n",
                "print(f\"Using dataset at: {DATASET_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize pipeline\n",
                "pipeline = DataPipeline(DATASET_PATH, img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
                "\n",
                "# Explore dataset structure\n",
                "stats = pipeline.explore_dataset()\n",
                "\n",
                "# Create stratified validation split\n",
                "pipeline.create_validation_split(val_ratio=0.15)\n",
                "\n",
                "# Create data generators\n",
                "train_gen, val_gen, test_gen = pipeline.create_generators(use_augmentation=True)\n",
                "\n",
                "# Calculate class weights for imbalance handling\n",
                "class_weights = Utils.calculate_class_weights(train_gen)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Samples\n",
                "Let's look at some representative X-ray images from the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pipeline.visualize_samples()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Stage 1: Feature Extraction\n",
                "In this stage, we freeze the ResNet-50 backbone and only train the custom classification head."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build model with frozen backbone\n",
                "model = ModelBuilder.build(img_size=IMG_SIZE, trainable_backbone=False)\n",
                "ModelBuilder.compile(model, learning_rate=1e-4)\n",
                "\n",
                "# Initialize trainer\n",
                "trainer = Trainer(model, output_dir=OUTPUT_DIR)\n",
                "\n",
                "# Train Stage 1\n",
                "history1 = trainer.train(\n",
                "    train_gen, val_gen, \n",
                "    epochs=8,\n",
                "    stage='stage1',\n",
                "    class_weight=class_weights\n",
                ")\n",
                "\n",
                "# Visualize training history\n",
                "trainer.plot_history(history1, 'stage1')\n",
                "Utils.print_best_metrics(history1, 'Stage 1')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Stage 2: Fine-Tuning\n",
                "Now we unfreeze the top layers of the backbone to fine-tune the feature representations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unfreeze layers\n",
                "base_model = model.layers[1]\n",
                "base_model.trainable = True\n",
                "# Keep bottom layers frozen to prevent overfitting\n",
                "for layer in base_model.layers[:140]:\n",
                "    layer.trainable = False\n",
                "\n",
                "# Recompile with lower learning rate\n",
                "ModelBuilder.compile(model, learning_rate=1e-5)\n",
                "\n",
                "# Train Stage 2\n",
                "history2 = trainer.train(\n",
                "    train_gen, val_gen, \n",
                "    epochs=5,\n",
                "    stage='stage2',\n",
                "    class_weight=class_weights\n",
                ")\n",
                "\n",
                "# Visualize fine-tuning history\n",
                "trainer.plot_history(history2, 'stage2')\n",
                "Utils.print_best_metrics(history2, 'Stage 2')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Save Model\n",
                "We save the final fine-tuned model for future inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define path for final model\n",
                "final_model_path = os.path.join(OUTPUT_DIR, \"final_pneumonia_model.h5\")\n",
                "\n",
                "# Save model\n",
                "model.save(final_model_path)\n",
                "print(f\"âœ… Final model saved to: {final_model_path}\")\n",
                "print(f\"   (Checkpoints also saved in: {trainer.checkpoint_dir})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comprehensive Evaluation\n",
                "Now that the model is trained, we evaluate its performance on the held-out test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Evaluator with the trained model and test generator\n",
                "evaluator = ModelEvaluator(model, test_gen)\n",
                "\n",
                "# Calculate and print metrics\n",
                "metrics = evaluator.calculate_metrics()\n",
                "\n",
                "# Detailed Classification Report\n",
                "evaluator.generate_classification_report();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performance Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "evaluator.plot_confusion_matrix()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "evaluator.plot_roc_curve()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "evaluator.plot_precision_recall_curve()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Explainability (Grad-CAM)\n",
                "We use Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize which regions of the X-ray the model focuses on when making predictions. This is crucial for verifying medical relevance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gradcam = GradCAMVisualizer(model)\n",
                "\n",
                "# Visualize a batch of random samples from the test set\n",
                "gradcam.visualize_batch(test_gen, num_samples=8)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}